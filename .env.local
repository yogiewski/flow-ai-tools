# Local environment overrides
# Configure your LLM settings here

LLM_BASE_URL=http://host.docker.internal
LLM_PORT=1234
LLM_API_FLAVOR=lmstudio
LLM_DEFAULT_MODEL=openai/gpt-oss-20b
MCP_BASE_URL=http://host.docker.internal:8000
FLOWHUB_HOOKS_ENABLED=false
FLOWHUB_WEBHOOK_URL=
