# Local environment overrides
# Configure your LLM settings here

LLM_BASE_URL=http://host.docker.internal
LLM_PORT=1234
LLM_API_FLAVOR=openai-compatible
LLM_DEFAULT_MODEL=openai/gpt-oss-20b
FLOWHUB_HOOKS_ENABLED=false
FLOWHUB_WEBHOOK_URL=
